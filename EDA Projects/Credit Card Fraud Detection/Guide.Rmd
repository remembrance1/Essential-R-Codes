---
output: 
  html_document
title: "Credit Card Fraud Detection - XGBOOST"
author: "Javier - EY"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions. SMOTE is used as an oversampling technique to balance out the dataset.

## Loading of Libraries

```{R message = F, warning = F}
setwd("C:/Users/zm679xs/Desktop/R/Essential-R-Codes/EDA Projects/Credit Card Fraud Detection")
library(ggplot2) # Data visualization
library(readr) # CSV file I/O, e.g. the read_csv function
library(caret)
library(DMwR) # smote
library(xgboost)
library(Matrix)
library(reshape) #melt
library(pROC) # AUC

# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory
load("ccdata.RData")
```

## Head of Data

```{R}
dim(ccdata)
head(ccdata)
```

## Split Data

Split data into train, test and cv using caret.

```{R}
## split into train, test, cv
set.seed(1900)
inTrain <- createDataPartition(y = ccdata$Class, p = .6, list = F) #60% train
train <- ccdata[inTrain,]
testcv <- ccdata[-inTrain,]
inTest <- createDataPartition(y = testcv$Class, p = .5, list = F) #20% test
test <- testcv[inTest,]
cv <- testcv[-inTest,]
train$Class <- as.factor(train$Class)
rm(inTrain, inTest, testcv) #20% cv
```

## Imbalance Dataset

Out of the 284,807 transactions, only 492 were classified as fraud cases and the rest were non-fraud. 

```{R}
table(ccdata$Class)
```

SMOTE is used to make the dataset more balanced.

```{R}
#using SMOTE instead
i <- grep("Class", colnames(train)) # Get index Class column
train_smote <- SMOTE(Class ~ ., as.data.frame(train), perc.over = 20000, perc.under=100)

#Identify the Predictors and the dependent variable, aka label.
predictors <- colnames(train_smote[-ncol(train_smote)]) #remove last column
#xgboost works only if the labels are numeric. Hence, convert the labels (Species) to numeric.
label <- as.numeric(train_smote[,ncol(train_smote)])

#Alas, xgboost works only if the numeric labels start from 0. Hence, subtract 1 from the label.
label <- as.numeric(train_smote[,ncol(train_smote)])-1
print(table(label))
```

## Setting Parameters for XGBoost

```{R}
# set parameters:
parameters <- list(
  # General Parameters
  booster            = "gbtree",          
  silent             = 0,                 
  # Booster Parameters
  eta                = 0.3,               
  gamma              = 0,                 
  max_depth          = 6,                 
  min_child_weight   = 1,                 
  subsample          = 1,                 
  colsample_bytree   = 1,                 
  colsample_bylevel  = 1,                 
  lambda             = 1,                 
  alpha              = 0,                 
  # Task Parameters
  objective          = "binary:logistic",   
  eval_metric        = "auc",
  seed               = 1900               
)
```

Explanation: 

  * Booster: gbtree = tree-based models
  * silent: 0 = enable messages 
  * eta: 0.3 = analogous learning rate in GBM. Makes the model more robust by shrinking the weights on each step
  * min_child_weight: 1 = used to control overfitting issue. Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree.
  * max_depth: 6 = maximum depth of a tree. Larger the depth, more complex the model, hence chance of overfitting. USually range is 0 to infinity.
  * subsample: 1 = controls number of samples supplied to a tree. Usually, 0.5-0.8
  * colsample_bytree: 1 = controls number of features supplied to a tree. Usually 0.5 to 0.9
  * lambda: 1 = controls L2 regularization. Avoid overfitting
  * alpha: 1 = controls L1 regularization on weights. More useful on high dimensional datasets
  * objective: binary:logistic = for binary classification
  * eval_metric: used to evaluatte a model's accuracy on validation data. 

## Parallel Backend (Not Used)

We can set a parallel backend to ensure faster computation. Make sure not to open several applications in backend as all cores will be used in the machine.

```{R eval = F}
#set parallel backend
> library(parallel)
> library(parallelMap) 
> parallelStartSocket(cpus = detectCores())

```

## Train Model

Train the model with the parameters set above and nrounds = 25 (increasing nrounds does not improve the model anymore). Plots show increasing train and cv AUC in the beginning and stagnating at later rounds as expected.

```{R result = F}
## Training of models
# Original
cv.nround = 150;  # Number of rounds. This can be set to a lower or higher value, if you wish, example: 150 or 250 or 300  
bst.cv <- xgb.cv(
  param=parameters,
  data = as.matrix(train_smote[,predictors]),
  label = label,
  nfold = 3,
  nrounds=cv.nround,
  prediction=T)

#Find where the minimum logloss occurred
min.loss.idx = which.max(bst.cv$evaluation_log[, test_auc_mean]) 
cat("Minimum logloss occurred in round : ", min.loss.idx, "\n")

# Minimum logloss
print(bst.cv$evaluation_log[min.loss.idx,])
```

## Predict
Predict with dataset and set threshold of 0.5

```{R}
## Make predictions
bst <- xgboost(
  param=parameters,
  data =as.matrix(train_smote[,predictors]), #training it without the output variable! 
  label = label,
  nrounds=min.loss.idx)

# Make prediction on the testing data.
test$prediction <- predict(bst, as.matrix(test[,predictors])) #here, I've removed the output variable....

test$prediction <- ifelse(test$prediction >= 0.5, 1 , 0)
```

## Confusion Matrix

Sensitivity (TPR) = 0.9991
Specificity (TNR) = 0.9135
Accuracy = 0.9989

```{R}
#Compute the accuracy of predictions.
confmatrix_table <- confusionMatrix(as.factor(test$prediction), as.factor(test$Class)) #sensitivity (TPR) = 0.9991, specificity = 0.9135
#accuracy = 0.9989
```


```{R}
plot_confusion_matrix <- function(test_df, sSubtitle) {
  tst <- data.frame(round(test_df$prediction,0), test_df$Class)
  opts <-  c("Predicted", "True")
  names(tst) <- opts
  cf <- plyr::count(tst)
  cf[opts][cf[opts]==0] <- "Not Fraud"
  cf[opts][cf[opts]==1] <- "Fraud"
  
  ggplot(data =  cf, mapping = aes(x = True, y = Predicted)) +
    labs(title = "Confusion matrix", subtitle = sSubtitle) +
    geom_tile(aes(fill = freq), colour = "grey") +
    geom_text(aes(label = sprintf("%1.0f", freq)), vjust = 1) +
    scale_fill_gradient(low = "lightblue", high = "Green") +
    theme_bw() + theme(legend.position = "none")
  
}

plot_confusion_matrix(test, paste("XGBoost with", paste("min logloss at round: ", min.loss.idx, "\n"),
                                  "Sensitivity:", round(confmatrix_table[[4]][1], 4), "\n",
                                  "Specificity:", round(confmatrix_table[[4]][2], 4)))
```

## Importance Matrix

Identify features that are most important

```{R}
##plot feature importance
importance_matrix <- xgb.importance(model = bst)
xgb.plot.importance(importance_matrix)
```

## ROC Curve
AUC = 0.956

```{R warning = F}
###############################################################
library(ROCR)

# Use ROCR package to plot ROC Curve
xgb.pred <- prediction(test$prediction, test$Class)
xgb.perf <- performance(xgb.pred, "tpr", "fpr")

plot(xgb.perf,
     avg="threshold",
     colorize=TRUE,
     lwd=1,
     main="ROC Curve w/ Thresholds",
     print.cutoffs.at=seq(0, 1, by=0.05),
     text.adj=c(-0.5, 0.5),
     text.cex=0.5)
grid(col="lightgray")
axis(1, at=seq(0, 1, by=0.1))
axis(2, at=seq(0, 1, by=0.1))
abline(v=c(0.1, 0.3, 0.5, 0.7, 0.9), col="lightgray", lty="dotted")
abline(h=c(0.1, 0.3, 0.5, 0.7, 0.9), col="lightgray", lty="dotted")
lines(x=c(0, 1), y=c(0, 1), col="black", lty="dotted")

auc_ROCR <- performance(xgb.pred, measure = "auc") #gives the AUC rate
auc_ROCR <- auc_ROCR@y.values[[1]] 
auc_ROCR 
#AUC = 0.956
```
